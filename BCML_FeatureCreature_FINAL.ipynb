{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"text-align: center\"> BiocompoundML </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BCML library\n",
    "from bcml import bcml_module as bcml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean training/testing folders between runs to prevent KeyError\n",
    "bcml.clean_training_testing(training=True, testing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>Required Input</mark> - Predictor Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor\n",
    "# -- The desired feature to be predicted\n",
    "__PREDICTOR = 'RON'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Universal Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__OPTIONS = {}\n",
    "\n",
    "# Network proxy (http://...)\n",
    "__OPTIONS['proxy'] = ''\n",
    "\n",
    "# HTTP request try count\n",
    "# -- To prevent errors from failed connection attempts due to unstable network conditions\n",
    "__OPTIONS['try_count'] = 5\n",
    "\n",
    "# Random seed (for repeatable results)\n",
    "# -- Must be a positive integer\n",
    "__OPTIONS['random_seed'] = None\n",
    "\n",
    "# Verbose mode\n",
    "__OPTIONS['verbose'] = True\n",
    "\n",
    "# Chunks (for retrieving PubChem info)\n",
    "# -- Chunks allow PCP to split IDs into smaller sized chunks, which helps prevent problems\n",
    "# -- with querying too many IDs\n",
    "__OPTIONS['chunks'] = 10\n",
    "\n",
    "# Plot\n",
    "__OPTIONS['plot'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model name (To save a new model or test an existing model)\n",
    "__OPTIONS['model_name'] = 'RON_model_new_LW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include user-provided features from PubChem\n",
    "__OPTIONS['user'] = False\n",
    "\n",
    "# Extract experimental features from PubChem\n",
    "__OPTIONS['experimental'] = False\n",
    "\n",
    "# Extract PaDEL-Descriptors from PubChem\n",
    "__OPTIONS['chemofeatures'] = True\n",
    "\n",
    "# Extract fingerprint features from PubChem\n",
    "# -- Will default to True if one of distance, cluster, or impute is marked True\n",
    "__OPTIONS['fingerprint'] = True\n",
    "\n",
    "# Use SMILES rather than CIDs \n",
    "# -- Requires SMILES in input files\n",
    "__OPTIONS['smiles'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run clustering\n",
    "__OPTIONS['cluster'] = False\n",
    "\n",
    "# Create a distance matrix\n",
    "# -- Will default to True if either cluster or impute are True\n",
    "__OPTIONS['distance'] = True\n",
    "\n",
    "# Impute missing values using K-NN imputation\n",
    "__OPTIONS['impute'] = True\n",
    "\n",
    "# Output data into numpy arrays\n",
    "__OPTIONS['txt'] = False\n",
    "\n",
    "# Output folder\n",
    "import os\n",
    "PATH = os.getcwd() #default \n",
    "__OPTIONS['outputdir'] = PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a New/Existing Model\n",
    "### <mark>Required Input</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a model?\n",
    "__TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training input file\n",
    "# -- A relative filepath pointing to the desired input file.\n",
    "# ---- 1) A tab-delimited .txt file with compound name, pubchem ID, and chemical features\n",
    "# ---- 2) A previously generated pickle file (.cluster .model or .features)\n",
    "\n",
    "#####   WARNING !!!   #####\n",
    "# -- The pickle datatype is inherently insecure. Pickle files can contain corrupt code and \n",
    "# -- executable commands that can contain malicious code. Make sure you trust the source of\n",
    "# -- your model.\n",
    "__TRAINING_INPUT = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boruta feature selection\n",
    "# -- Reduces uncharacterizing features\n",
    "__OPTIONS['selection'] = True\n",
    "\n",
    "# Split value (threshold for classification)\n",
    "# -- If None, median value is used\n",
    "__OPTIONS['split_value'] = None\n",
    "\n",
    "# Error correct for potentially erroneous values in the training set\n",
    "__OPTIONS['error_correct'] = True\n",
    "\n",
    "# Cross-validate the model -- currently unavailable\n",
    "__OPTIONS['cross_validate'] = False\n",
    "\n",
    "# Insert sample weights\n",
    "# -- Requires sample weights in the input file\n",
    "__OPTIONS['weight'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trained_model and training variables\n",
    "trained_model = False\n",
    "training = False\n",
    "\n",
    "if __TRAIN:\n",
    "    trained_model = bcml.train_model(__TRAINING_INPUT, __PREDICTOR, __OPTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test a New/Existing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <mark>Required Input</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model?\n",
    "__TEST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test input (_TEST_INPUT_FILE and/or _TEST_INPUT_DIRECTORY required)\n",
    "\n",
    "# Test Input File\n",
    "# -- A tab-delimited .txt file with compound name and PubChem ID(if using file pubchem IDs are required)\n",
    "__TEST_INPUT_FILE = None\n",
    "\n",
    "# Test Input Directory\n",
    "# -- A directory containing .sdf files (when PubChem IDs are unavailable)\n",
    "__TEST_INPUT_DIRECTORY = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize testing, test, and prediction variables\n",
    "from bcml import bcml_module as bcml\n",
    "testing = True\n",
    "test = True\n",
    "prediction = True\n",
    "\n",
    "if __TEST:\n",
    "    [testing, test, prediction] = bcml.test_model(trained_model, __TEST_INPUT_FILE, \n",
    "                                                  __TEST_INPUT_DIRECTORY, __PREDICTOR, __OPTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Features Using the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  \n",
    "#  \n",
    "# <div style=\"text-align: center\"> FeatureCreature </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__RUN_FEATURE_CREATURE = True\n",
    "__FC_MODEL_NAME = __OPTIONS.get('model_name')\n",
    "\n",
    "if not ((__TRAIN or __FC_MODEL_NAME) and (__TEST and __RUN_FEATURE_CREATURE)):\n",
    "    # Stop running jupyter notebook\n",
    "    # FeatureCreature requires compound characterization using BCML (__TEST), as well as\n",
    "    # training data from BCML __TRAIN or a previously saved FeatureCreature model __FC_MODEL_NAME\n",
    "    assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "\n",
    "# Explanability libraries\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "# Chemistry libraries\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from IPython.display import display, Image\n",
    "\n",
    "import imp\n",
    "import os\n",
    "import zipfile\n",
    "from sys import platform\n",
    "if platform == 'darwin':\n",
    "    if os.path.isdir('./indigo-python-1.2.3.r0-mac') is False:\n",
    "        zipref = zipfile.ZipFile('./indigo-python-1.2.3.r0-mac.zip', 'r')\n",
    "        zipref.extractall('.')\n",
    "    indigo = imp.load_source('indigo', 'indigo-python-1.2.3.r0-mac/indigo.py')\n",
    "    indigo_renderer = imp.load_source('indigo_renderer', 'indigo-python-1.2.3.r0-mac/indigo_renderer.py')\n",
    "elif platform == \"linux\" or platform == \"linux2\":\n",
    "    if os.path.isdir('./indigopython130_linux') is False:\n",
    "        zipref = zipfile.ZipFile('./indigopython130_linux.zip', 'r')\n",
    "        zipref.extractall('.')\n",
    "    indigo = imp.load_source('indigo', 'indigopython130_linux/indigo.py')\n",
    "    indigo_renderer = imp.load_source('indigo_renderer', 'indigopython130_linux/indigo_renderer.py')\n",
    "elif platform == \"win32\" or platform == \"win64\":\n",
    "    if os.path.isdir('./indigopython130_win') is False:\n",
    "        zipref = zipfile.ZipFile('./indigopython130_win.zip', 'r')\n",
    "        zipref.extractall('.')\n",
    "    indigo = imp.load_source('indigo', 'indigopython130_win/indigo.py')\n",
    "    indigo_renderer = imp.load_source('indigopython130_win/indigo_renderer.py')\n",
    "\n",
    "indigo = indigo.Indigo()\n",
    "indigoRenderer = indigo_renderer.IndigoRenderer(indigo)\n",
    "\n",
    "# Other libraries\n",
    "import glob\n",
    "import dill\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train FeatureCreature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option - Save FeatureCreature Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "__SAVE_FEATURECREATURE = True\n",
    "__BUILD_FEATURECREATURE_EXPLAINER = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map feature IDs to .sdf patterns\n",
    "feature_list = np.genfromtxt(\"feature_list.txt\", dtype=\"str\", delimiter=\"\\t\", comments=\"%\")\n",
    "feature_ids = [a for a, b in feature_list]\n",
    "feature_patterns = [b for a, b in feature_list]\n",
    "\n",
    "feature_dict = {feature_patterns[i]:feature_ids[i] for i in range(len(feature_ids))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not __TRAIN:\n",
    "    trained_model = bcml.existing_training_model('pre-built_models/'+__FC_MODEL_NAME+ \".model\", __OPTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = False\n",
    "if __BUILD_FEATURECREATURE_EXPLAINER:\n",
    "    # Load training data and process into compound-feature matrix\n",
    "    training_cpds = trained_model.input.compound\n",
    "    cpd_names = list(training_cpds.keys())\n",
    "    fc_features = list(trained_model.input.compound[cpd_names[0]]['padelhash'].keys())\n",
    "    for feat in fc_features:\n",
    "        if feat == 'Name':\n",
    "            fc_features.remove(feat)\n",
    "            break\n",
    "    \n",
    "    fc_training = np.zeros((len(training_cpds), len(fc_features)), dtype=np.float64)\n",
    "    for index, value in np.ndenumerate(fc_training):\n",
    "        compound = training_cpds[cpd_names[index[0]]]['padelhash']\n",
    "        feature = fc_features[index[1]]\n",
    "        fc_training[index] = float(compound[feature])\n",
    "          \n",
    "           \n",
    "    # Remove invariable features\n",
    "    reduced_X = fc_training[:,np.where(fc_training.var(axis=0)!=0)[0]]\n",
    "    reduced_feature_ids = [feature_ids[i] for i in np.where(fc_training.var(axis=0)!=0)[0]]\n",
    "    reduced_feature_patterns = [feature_patterns[i] for i in np.where(fc_training.var(axis=0)!=0)[0]]\n",
    "    \n",
    "    categorical_features = range(len(reduced_feature_ids))\n",
    "    categorical_names = {}\n",
    "    for feature in categorical_features:\n",
    "        le = sklearn.preprocessing.LabelEncoder()\n",
    "        le.fit(reduced_X[:,feature])\n",
    "        categorical_names[feature] = le.classes_\n",
    "    \n",
    "    explainer = lime.lime_tabular.LimeTabularExplainer(reduced_X, verbose=True,\n",
    "                                                       feature_names=reduced_feature_patterns,\n",
    "                                                       class_names=['Low %s' % __PREDICTOR,'High %s' % __PREDICTOR],\n",
    "                                                       categorical_features=categorical_features,\n",
    "                                                       categorical_names=categorical_names, kernel_width=3)\n",
    "    \n",
    "       \n",
    "    explainer.clf = sklearn.ensemble.RandomForestClassifier(n_estimators=512, \n",
    "                                                            oob_score=True, n_jobs=-1, \n",
    "                                                            class_weight=\"balanced\")\n",
    "    explainer.clf.fit(X=reduced_X, y=trained_model.predictors)\n",
    "    explainer.feature_ids = reduced_feature_ids\n",
    "    \n",
    "    if __SAVE_FEATURECREATURE:\n",
    "        filename = 'pre-built_models/'+__FC_MODEL_NAME + '.featurecreature'\n",
    "        with open(filename, 'wb') as fid:\n",
    "            dill.dump(explainer, fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict Using FeatureCreature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not explainer:\n",
    "    filename = 'pre-built_models/'+__FC_MODEL_NAME + '.featurecreature'\n",
    "    with open(filename, 'rb') as fid:\n",
    "        explainer = dill.load(fid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FeatureCreature Image Coloring Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each pattern, iterate atoms and map explainability score -\n",
    "# results are cumulative, so negative and positive values obliterate\n",
    "def getAtomsActivity (m, patterns):\n",
    "    matcher = indigo.substructureMatcher(m)\n",
    "    atom_values = defaultdict(float)\n",
    "    for pattern, value in patterns:\n",
    "        try:\n",
    "            query = indigo.loadQueryMolecule(pattern)\n",
    "            for match in matcher.iterateMatches(query):\n",
    "                for qatom in query.iterateAtoms():\n",
    "                    atom = match.mapAtom(qatom)\n",
    "                    atom_values[atom.index()] += value / query.countAtoms()\n",
    "        except:\n",
    "            pass\n",
    "    return atom_values\n",
    "\n",
    "# Convert atom values to color scores: blue direction = negative, red direction = positive\n",
    "def addColorSGroups (m, atom_values):\n",
    "    min_value = min(atom_values.values())\n",
    "    max_value = max(atom_values.values())\n",
    "    centered_value = (min_value + max_value) / 2.\n",
    "    for atom_index, atom_value in atom_values.items():\n",
    "        if atom_value < 0.:\n",
    "            color = \"0, 0, %f\" % abs(atom_value / centered_value)\n",
    "        elif atom_value > 0.:\n",
    "            color = \"%f, 0, 0\" % abs(atom_value / centered_value)\n",
    "        m.addDataSGroup([atom_index], [], \"color\", color)\n",
    "    return min_value, max_value\n",
    "\n",
    "# Take mol file and pattern list and associate these patterns with the atoms\n",
    "# and bonds and color them, based on the explainability results of LIME\n",
    "def assignColorGroups (m, patterns):\n",
    "    atom_values = getAtomsActivity(m, patterns)\n",
    "    min_value, max_value = addColorSGroups(m, atom_values)\n",
    "    return min_value, max_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Process Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Link sdf files of test compounds\n",
    "compounds = []\n",
    "if __TEST and __TEST_INPUT_FILE:\n",
    "    compounds += glob.glob('bcml/Chemoinformatics/db/testing/*.sdf')\n",
    "if __TEST and __TEST_INPUT_DIRECTORY:\n",
    "    compounds += glob.glob(__TEST_INPUT_DIRECTORY + '/*.sdf')\n",
    "\n",
    "# Map PubChem IDs to compound names\n",
    "if __TEST_INPUT_FILE:\n",
    "    pubchem_id_dict = {}\n",
    "    for i in range(len(testing.compounds)):\n",
    "        pubchem_id_dict[testing.compounds[i]['PubChem']] = testing.compounds[i]['Name']\n",
    "\n",
    "\n",
    "# Create a model using the predictions above\n",
    "predict_fn = lambda x: explainer.clf.predict_proba(x).astype(float)\n",
    "    \n",
    "\n",
    "# Split value for displaying in PNG\n",
    "if __OPTIONS.get('split_value') is not None:\n",
    "    __SPLIT_VALUE = __OPTIONS.get('split_value')\n",
    "else:\n",
    "    __SPLIT_VALUE = np.median(trained_model.predictor_values)\n",
    "    \n",
    "\n",
    "# Load testing data\n",
    "test_cpds = test.compounds\n",
    "fc_feature_ids = explainer.feature_ids\n",
    "fc_feature_patterns = explainer.feature_names\n",
    "\n",
    "fc_test = np.zeros((len(test_cpds), len(fc_feature_ids)), dtype=np.float64)\n",
    "for index, value in np.ndenumerate(fc_test):\n",
    "    compound = test_cpds[index[0]]['padelhash']\n",
    "    feature = fc_feature_ids[index[1]]\n",
    "    fc_test[index] = float(compound[feature])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate .png files of test compounds\n",
    "import datetime\n",
    "currentDT = datetime.datetime.now()\n",
    "for row, filename in enumerate(compounds):\n",
    "    id_name = filename.split('/')[-1][:-4]\n",
    "    \n",
    "    #Collect explanations from LIME\n",
    "    exp = explainer.explain_instance(fc_test[row], predict_fn, num_features=len(fc_feature_patterns),\n",
    "                                     top_labels=1, verbose=True, num_samples=5000)\n",
    "\n",
    "    #Load molecule\n",
    "    mol = indigo.iterateSDFile(filename)\n",
    "    m = mol.at(0)\n",
    "    patterns = []\n",
    "    #Find the local explanation: exp.local_exp[1]\n",
    "    intercept = list(exp.intercept.keys())[0]    \n",
    "    local_prob = list(exp.intercept.values())[0]\n",
    "    prob = exp.predict_proba[intercept]\n",
    "    for k, v in exp.local_exp.items():\n",
    "        for (num, val) in v:\n",
    "        #Map the explanation to the feature, if it is present in the molecule move forward\n",
    "            if float(exp.domain_mapper.feature_values[num]) == 1.:\n",
    "                if abs(val) != 0.:\n",
    "                    patterns.append((fc_feature_patterns[num],val))\n",
    "        \n",
    "    #Draw molecules\n",
    "    indigo.setOption(\"render-atom-ids-visible\", \"false\");\n",
    "    indigo.setOption(\"render-atom-color-property\", \"color\")\n",
    "    indigo.setOption('render-coloring', False)\n",
    "    indigo.setOption('render-comment-font-size', 32)\n",
    "    indigo.setOption('render-bond-line-width', 2.0)\n",
    "    indigo.setOption(\"render-margins\", 100, 1);    \n",
    "    try:\n",
    "        indigo.setOption('render-comment', '%s (%.2f%% probability - %s > %.2f)' % (pubchem_id_dict[id_name],\n",
    "                                                                   100*prediction[id_name],\n",
    "                                                                   __PREDICTOR, __SPLIT_VALUE))\n",
    "    except:\n",
    "        indigo.setOption('render-comment', '%s (%.2f%% proabbility - %s > %.2f)' % (id_name, \n",
    "                                                                   100*prediction[id_name],\n",
    "                                                                   __PREDICTOR, __SPLIT_VALUE))\n",
    "    try:\n",
    "        assignColorGroups(m, patterns)\n",
    "    except:\n",
    "        pass\n",
    "    import os\n",
    "    result_folder = bcml.check_results_folder(__OPTIONS.get('outputdir'), currentDT, __PREDICTOR)\n",
    "    renderfile = result_folder + str(id_name) + \".png\"\n",
    "    indigoRenderer.renderToFile(m, renderfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('All done! :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
