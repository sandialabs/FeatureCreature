{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries of interest.\n",
    "# Numerical libraries\n",
    "import sklearn #this is the main machine learning library\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np #this is the numeric library\n",
    "import scipy.stats as stats\n",
    "\n",
    "#OS libraries\n",
    "import urllib #this allows us to access remote files\n",
    "import urllib2\n",
    "import os\n",
    "from collections import OrderedDict, defaultdict\n",
    "import imp\n",
    "import sys\n",
    "\n",
    "#BCML libraries\n",
    "from bcml.Parser import read_training as rt\n",
    "from bcml.Parser import build_training as bt\n",
    "from bcml.PubChemUtils import pubchempy_utils as pcp\n",
    "from bcml.Chemoinformatics import chemofeatures as cf\n",
    "from bcml.Train import train_model as tm\n",
    "from bcml.Parser import read_testing as rtest\n",
    "from bcml.Parser import build_testing as btest\n",
    "\n",
    "\n",
    "# Visualization libraries\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Image\n",
    "\n",
    "# Explanability libraries\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "\n",
    "# Chemistry libraries\n",
    "indigo = imp.load_source('indigo', 'indigo-python-1.2.3.r0-mac/indigo.py')\n",
    "indigo_renderer = imp.load_source('indigo_renderer', 'indigo-python-1.2.3.r0-mac/indigo_renderer.py')\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import Draw\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Train:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def load(self, filename, identifier):\n",
    "        train = rt.Read(filename, identifier, id_name=\"PubChem\")\n",
    "        # Load SDFs from NCBI\n",
    "        training_data = pcp.Collect(train.compounds, sdf=True, chunks=20, id_name='PubChem', predictors=train.predictors, proxy=None)\n",
    "        training_data = cf.Update(training_data, remove_static=False)\n",
    "        # Run PaDEL-Descriptor to extract 6150 substructural features\n",
    "        training_data.update(padel=True)\n",
    "        ids = [id for id, compound in dict.iteritems(OrderedDict(sorted(training_data.compound.items(), key=lambda t: t[0])))]\n",
    "        # Create machine learning model using a Random Forest Classifier\n",
    "        predictors = []\n",
    "        names = []\n",
    "        compounds = []\n",
    "        training_compounds = OrderedDict(sorted(training_data.compound.items(), key=lambda t: t[0]))\n",
    "        # Preprocess data\n",
    "        for identifier, compound in dict.iteritems(training_compounds):\n",
    "            predictors.append(training_compounds[identifier]['predictor'])\n",
    "            compounds.append(training_compounds[identifier])\n",
    "            names.append(identifier)\n",
    "        predictor_values = np.array(predictors, '|S4').astype(np.float)\n",
    "        #Generate predictor values: y\n",
    "        predict = np.zeros(len(predictor_values), dtype=int)\n",
    "        for i, value in np.ndenumerate(predictor_values):\n",
    "            if value >= np.median(predictor_values):\n",
    "                predict[i] = 1\n",
    "        rows = len(predict)\n",
    "        # Load the names of the features\n",
    "        feature_names = []\n",
    "        for compound in compounds:\n",
    "            feature_names = sorted(compound['padelhash'].keys())\n",
    "        for c in feature_names:\n",
    "            if c == 'Name':\n",
    "                feature_names.remove(c)\n",
    "        columns = len(feature_names)\n",
    "        data_table = np.zeros((rows, columns), dtype=np.float64)\n",
    "        # Load the training values: X\n",
    "        for index, value in np.ndenumerate(data_table):\n",
    "            compound = compounds[index[0]]['padelhash']\n",
    "            feature = list(feature_names)[index[1]]\n",
    "            data_table[index] = float(compound[feature])\n",
    "        self.data_table = data_table\n",
    "        self.feature_names = feature_names\n",
    "        self.compounds = compounds\n",
    "        self.predict = predict\n",
    "        self.predictor_values = predictor_values\n",
    "        self.training_data = training_data\n",
    "        self.training_compounds = training_compounds\n",
    "        self.names = names\n",
    "    def reduce_features(self):\n",
    "        feature_list = np.genfromtxt(\"feature_list.txt\", dtype=\"str\", delimiter=\"\\t\", comments=\"%\")\n",
    "        feature_ids = [a for a, b in feature_list]\n",
    "        feature_patterns = [b for a, b in feature_list]\n",
    "        data_table = self.data_table\n",
    "        names = self.names\n",
    "        # Remove invariable features\n",
    "        reduced_X = data_table[:,np.where(data_table.var(axis=0)!=0)[0]]\n",
    "        reduced_feature_ids = [feature_ids[i] for i in np.where(data_table.var(axis=0)!=0)[0]]\n",
    "        reduced_feature_patterns = [feature_patterns[i] for i in np.where(data_table.var(axis=0)!=0)[0]]\n",
    "        rows = len(names)\n",
    "        columns = len(reduced_feature_ids)\n",
    "        reduced_data_table = np.zeros((rows, columns), dtype=np.float64)\n",
    "        # Load the training values: X\n",
    "        for index, value in np.ndenumerate(reduced_data_table):\n",
    "            compound = self.compounds[index[0]]['padelhash']\n",
    "            feature = list(reduced_feature_ids)[index[1]]\n",
    "            reduced_data_table[index] = float(compound[feature])\n",
    "        self.reduced_data_table = reduced_data_table\n",
    "        self.reduced_feature_ids = reduced_feature_ids\n",
    "        self.reduced_feature_patterns = reduced_feature_patterns\n",
    "    def learn(self):\n",
    "        self.clf = sklearn.ensemble.RandomForestClassifier(n_estimators=512, oob_score=True, n_jobs=-1, class_weight=\"balanced\")\n",
    "        self.clf.fit(X=self.reduced_data_table, y=self.predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CrossValidate:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.clf = sklearn.ensemble.RandomForestClassifier(n_estimators=512, oob_score=True, n_jobs=-1, class_weight=\"balanced\")\n",
    "    def cross_validation(self):\n",
    "        self.clf.fit(X=self.model.reduced_data_table, y=self.model.predict)\n",
    "        def _run_cv(cv, clf, y, X):\n",
    "            ys = []\n",
    "            for train_idx, valid_idx in cv:\n",
    "                clf.fit(X=X[train_idx], y=y[train_idx])\n",
    "                cur_pred = clf.predict(X[valid_idx])\n",
    "                ys.append((y[valid_idx], cur_pred))\n",
    "            acc = np.fromiter(map(lambda tp: sklearn.metrics.accuracy_score(tp[0], tp[1]), ys), np.float)\n",
    "            prec = np.fromiter(map(lambda tp: sklearn.metrics.precision_score(tp[0], tp[1]), ys), np.float)\n",
    "            recall = np.fromiter(map(lambda tp: sklearn.metrics.recall_score(tp[0], tp[1]), ys), np.float)\n",
    "            roc = np.fromiter(map(lambda tp: sklearn.metrics.roc_auc_score(tp[0], tp[1]), ys), np.float)\n",
    "            print_line = (\"\\tAccuracy: %0.4f +/- %0.4f\" % (np.mean(acc), np.std(acc) * 2))\n",
    "            print(print_line)\n",
    "            print_line = (\"\\tPrecision: %0.4f +/- %0.4f\" % (np.mean(prec), np.std(prec) * 2))\n",
    "            print(print_line)\n",
    "            print_line = (\"\\tRecall: %0.4f +/- %0.4f\" % (np.mean(recall), np.std(recall) * 2))\n",
    "            print(print_line)\n",
    "            print_line = (\"\\tReceiver Operator, AUC: %0.4f +/- %0.4f\" % (np.mean(roc), np.std(roc) * 2))\n",
    "            print(print_line)\n",
    "\n",
    "# 50% hold-out very conservative uses half the data for training and half the data for testing\n",
    "# Likely closer accuracy match to novel dataset\n",
    "\n",
    "        cv = sklearn.cross_validation.StratifiedShuffleSplit(self.model.predict, n_iter=100, test_size=0.5)\n",
    "        print(\"For 100 resamples at 50%\")\n",
    "        _run_cv(cv, self.clf, self.model.predict, self.model.reduced_data_table)\n",
    "\n",
    "# 10-fold cross-validation, less conservative uses 90% of the data for training and 10% of the data for testing\n",
    "# Likely closer accuracy between model and training data\n",
    "\n",
    "        cv = sklearn.cross_validation.StratifiedKFold(self.model.predict, n_folds=10)\n",
    "        print(\"For 10-fold cross validation\")\n",
    "        _run_cv(cv, self.clf, self.model.predict, self.model.reduced_data_table)\n",
    "    def visualize(self, filename):\n",
    "        plt.clf()\n",
    "        sns.set_style(\"darkgrid\")\n",
    "        # Initialize the figure\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlim([-0.01, 1.01])\n",
    "        plt.ylim([-0.01, 1.01])\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.title('Mean Receiver operating characteristic')\n",
    "        tprs = []\n",
    "        base_fpr = np.linspace(0, 1, 101)\n",
    "        # Run 10 instances of 10X cross_validation\n",
    "        for i in range(10):\n",
    "            X_train, X_test, y_train, y_test = sklearn.cross_validation.train_test_split(self.model.reduced_data_table, self.model.predict, test_size=0.1)\n",
    "            self.clf.fit(X_train, y_train)\n",
    "            y_pred = self.clf.predict_proba(X_test)[:, 1]\n",
    "            fpr, tpr, _ = sklearn.metrics.roc_curve(y_test, y_pred)\n",
    "            plt.plot(fpr, tpr, 'b', alpha=0.15)\n",
    "            tpr = np.interp(base_fpr, fpr, tpr)\n",
    "            tpr[0] = 0.0\n",
    "            tprs.append(tpr)\n",
    "        # Get average and std for cross_validation\n",
    "        tprs = np.array(tprs)\n",
    "        mean_tprs = tprs.mean(axis=0)\n",
    "        std = tprs.std(axis=0)\n",
    "        tprs_upper = np.minimum(mean_tprs + std, 1)\n",
    "        tprs_lower = mean_tprs - std\n",
    "        #Plot multiple ROCs\n",
    "        plt.plot(base_fpr, mean_tprs, 'b')\n",
    "        plt.fill_between(base_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.3)\n",
    "        plt.axes().set_aspect('equal')\n",
    "        plt.savefig(filename)\n",
    "        Image(filename = filename)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Testing:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def load(self, filename):\n",
    "        testing_data = pcp.Collect(local=filename, sdf=True)\n",
    "        testing_data = cf.Update(testing_data, remove_static=False)\n",
    "        testing_data.update(padel=True)\n",
    "        testing_compounds = OrderedDict(sorted(testing_data.compound.items(), key=lambda t: t[0]))\n",
    "        compounds = []\n",
    "        for identifier, compound in dict.iteritems(testing_compounds):\n",
    "            compounds.append(testing_compounds[identifier])\n",
    "        #self.filename = filename\n",
    "        #testing = rtest.Read(filename, id_name=\"PubChem\")\n",
    "        #testing_data = pcp.Collect(testing.compounds, sdf=True, chunks=20, id_name='PubChem', proxy=None)\n",
    "        #pubchem_id_dict = {}\n",
    "        #for compound in testing.compounds:\n",
    "        #    pubchem_id_dict[compound['PubChem']] = compound['Name']\n",
    "        #    testing_data = cf.Update(testing_data, remove_static=False)\n",
    "        # Run PaDEL-Descriptor to extract 6150 substructural features\n",
    "        #testing_data.update(padel=True)\n",
    "        feature_names = []\n",
    "        #testing_compounds = OrderedDict(sorted(testing_data.compound.items(), key=lambda t: t[0]))\n",
    "        #compounds = []\n",
    "        #for identifier, compound in dict.iteritems(testing_compounds):\n",
    "        #    compounds.append(testing_compounds[identifier])\n",
    "        # Load the names of the features\n",
    "        feature_names = []\n",
    "        for compound in compounds:\n",
    "            feature_names = sorted(compound['padelhash'].keys())\n",
    "        for c in feature_names:\n",
    "            if c == 'Name':\n",
    "                feature_names.remove(c)\n",
    "        columns = len(feature_names)\n",
    "        rows = len(testing_data.compound)\n",
    "        test = np.zeros((rows, columns,), dtype=np.float64)\n",
    "        compounds = []\n",
    "        testing_names = []\n",
    "        testing_data.compound = OrderedDict(sorted(testing_data.compound.items(), key=lambda t: t[0]))\n",
    "        for id, compound in testing_data.compound.iteritems():\n",
    "            compounds.append(compound)\n",
    "            testing_names.append(id)\n",
    "        self.testing_data = testing_data\n",
    "        self.compounds = compounds\n",
    "        self.testing_names = testing_names\n",
    "        #self.pubchem_id_dict = pubchem_id_dict\n",
    "        rows = len(testing_names)\n",
    "        # Load the names of the features\n",
    "        feature_names = []\n",
    "        for compound in compounds:\n",
    "            feature_names = sorted(compound['padelhash'].keys())\n",
    "        for c in feature_names:\n",
    "            if c == 'Name':\n",
    "                feature_names.remove(c)\n",
    "        columns = len(feature_names)\n",
    "        testing_data_table = np.zeros((rows, columns), dtype=np.float64)\n",
    "        # Load the training values: X\n",
    "        for index, value in np.ndenumerate(testing_data_table):\n",
    "            compound = compounds[index[0]]['padelhash']\n",
    "            feature = list(feature_names)[index[1]]\n",
    "            testing_data_table[index] = float(compound[feature])\n",
    "        self.feature_names = feature_names\n",
    "        self.testing_data_table = testing_data_table\n",
    "    def reduce_features(self, train):\n",
    "        feature_list = np.genfromtxt(\"feature_list.txt\", dtype=\"str\", delimiter=\"\\t\", comments=\"%\")\n",
    "        feature_ids = [a for a, b in feature_list]\n",
    "        feature_patterns = [b for a, b in feature_list]\n",
    "        data_table = self.testing_data_table\n",
    "        names = self.testing_names\n",
    "        # Remove invariable features\n",
    "        reduced_feature_ids = train.reduced_feature_ids\n",
    "        reduced_feature_patterns = train.reduced_feature_patterns\n",
    "        rows = len(names)\n",
    "        columns = len(reduced_feature_ids)\n",
    "        reduced_data_table = np.zeros((rows, columns), dtype=np.float64)\n",
    "        # Load the training values: X\n",
    "        for index, value in np.ndenumerate(reduced_data_table):\n",
    "            compound = self.compounds[index[0]]['padelhash']\n",
    "            feature = list(reduced_feature_ids)[index[1]]\n",
    "            reduced_data_table[index] = float(compound[feature])\n",
    "        self.reduced_data_table = reduced_data_table\n",
    "        self.reduced_feature_ids = reduced_feature_ids\n",
    "        self.reduced_feature_patterns = reduced_feature_patterns \n",
    "    def learn(self, train):\n",
    "        train.clf.fit(X=train.data_table, y=train.predict)\n",
    "        print(train.clf.predict_proba(self.testing_data_table))\n",
    "        print(self.testing_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the similarity of training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VisualizeTesting():\n",
    "    def __init__(self, train, testing):\n",
    "        self.train = train\n",
    "        self.testing = testing\n",
    "    def pca(self):\n",
    "        self.pca = PCA()\n",
    "        self.pca.fit(self.train.data_table)\n",
    "        self.pc_train = self.pca.transform(self.train.data_table)\n",
    "        self.pc_testing = self.pca.transform(self.testing.testing_data_table)\n",
    "    def viz_explained(self, filename):\n",
    "        plt.clf()\n",
    "        summed_variance = np.cumsum(self.pca.explained_variance_ratio_)\n",
    "        plt.axhline(summed_variance[4], color=\"mediumpurple\")\n",
    "        barlist = plt.bar(range(25), summed_variance[:25], color=\"steelblue\")\n",
    "        thresh = np.where(summed_variance[:25] <= summed_variance[4])[0]\n",
    "        for t in thresh:\n",
    "            barlist[t].set_color('mediumpurple')\n",
    "        plt.axhline(0.9, color=\"darkred\")\n",
    "        thresh = np.where(summed_variance[:25] >= 0.9)[0]\n",
    "        for t in thresh:\n",
    "            barlist[t].set_color('darkred')\n",
    "        plt.title(\"Variance Explained by Each PC\")\n",
    "        plt.savefig(filename)\n",
    "        Image(filename = filename)\n",
    "    def viz_xx(self, filename):\n",
    "        plt.clf()\n",
    "        pc = self.pc_train\n",
    "        pc_test = self.pc_testing\n",
    "        f, axarr = plt.subplots(4, 4, sharex='col', sharey='row')\n",
    "        axarr[0, 0].set_title(\"PC1\")\n",
    "        axarr[0, 1].set_title(\"PC2\")\n",
    "        axarr[0, 2].set_title(\"PC3\")\n",
    "        axarr[0, 3].set_title(\"PC4\")\n",
    "        axarr[0, 0].set_ylabel(\"PC2\")\n",
    "        axarr[1, 0].set_ylabel(\"PC3\")\n",
    "        axarr[2, 0].set_ylabel(\"PC4\")\n",
    "        axarr[3, 0].set_ylabel(\"PC5\")\n",
    "        axarr[0, 0].scatter(pc[:, 1], pc[:, 0])\n",
    "        axarr[0, 0].scatter(pc_test[:, 1], pc_test[:, 0], color=\"red\")\n",
    "        axarr[1, 0].scatter(pc[:, 2], pc[:, 0])\n",
    "        axarr[1, 0].scatter(pc_test[:, 2], pc_test[:, 0], color=\"red\")\n",
    "        axarr[2, 0].scatter(pc[:, 3], pc[:, 0])\n",
    "        axarr[2, 0].scatter(pc_test[:, 3], pc_test[:, 0], color=\"red\")\n",
    "        axarr[3, 0].scatter(pc[:, 4], pc[:, 0])\n",
    "        axarr[3, 0].scatter(pc_test[:, 4], pc_test[:, 0], color=\"red\")\n",
    "        axarr[0, 1].axis('off')\n",
    "        axarr[1, 1].scatter(pc[:, 2], pc[:, 1])\n",
    "        axarr[1, 1].scatter(pc_test[:, 2], pc_test[:, 1], color=\"red\")\n",
    "        axarr[2, 1].scatter(pc[:, 3], pc[:, 1])\n",
    "        axarr[2, 1].scatter(pc_test[:, 3], pc_test[:, 1], color=\"red\")\n",
    "        axarr[3, 1].scatter(pc[:, 4], pc[:, 1])\n",
    "        axarr[3, 1].scatter(pc_test[:, 4], pc_test[:, 1], color=\"red\")\n",
    "        axarr[0, 2].axis('off')\n",
    "        axarr[1, 2].axis('off')\n",
    "        axarr[2, 2].scatter(pc[:, 3], pc[:, 2])\n",
    "        axarr[2, 2].scatter(pc_test[:, 3], pc_test[:, 2], color=\"red\")\n",
    "        axarr[3, 2].scatter(pc[:, 4], pc[:, 2])\n",
    "        axarr[3, 2].scatter(pc_test[:, 4], pc_test[:, 2], color=\"red\")\n",
    "        axarr[0, 3].axis('off')\n",
    "        axarr[1, 3].axis('off')\n",
    "        axarr[2, 3].axis('off')\n",
    "        axarr[3, 3].scatter(pc[:, 4], pc[:, 3])\n",
    "        axarr[3, 3].scatter(pc_test[:, 4], pc_test[:, 3], color=\"red\")\n",
    "        plt.savefig(filename)\n",
    "        Image(filename = filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LIME:\n",
    "    def __init__(self, training, testing, identifier):\n",
    "        self.training = training\n",
    "        self.testing = testing\n",
    "        self.identifier = identifier\n",
    "        training.clf.fit(training.reduced_data_table, training.predict)\n",
    "        self.predict_fn = lambda x: training.clf.predict_proba(x).astype(float)\n",
    "        categorical_features = range(len(training.reduced_feature_patterns))\n",
    "        categorical_names = {}\n",
    "        for feature in categorical_features:\n",
    "            le = sklearn.preprocessing.LabelEncoder()\n",
    "            le.fit(training.reduced_data_table[:, feature])\n",
    "            categorical_names[feature] = le.classes_\n",
    "        explainer = lime.lime_tabular.LimeTabularExplainer(testing.reduced_data_table, verbose=True,\n",
    "                                                           feature_names=training.reduced_feature_patterns,\n",
    "                                                           class_names = [str('Low'+ identifier), str('High' + identifier)], \n",
    "                                                           categorical_features=categorical_features,\n",
    "                                                           categorical_names=categorical_names, kernel_width = 3)\n",
    "        self.explainer = explainer\n",
    "    def molecule(self, local=False):\n",
    "        import imp\n",
    "        indigo = imp.load_source('indigo', 'indigo-python-1.2.3.r0-mac/indigo.py')\n",
    "        indigo_renderer = imp.load_source('inigo_renderer', 'indigo-python-1.2.3.r0-mac/indigo_renderer.py')\n",
    "        indigo = indigo.Indigo()\n",
    "        indigoRenderer = indigo_renderer.IndigoRenderer(indigo)\n",
    "        def getAtomsActivity (m, patterns):\n",
    "            matcher = indigo.substructureMatcher(m)\n",
    "            atom_values = defaultdict(float)\n",
    "            for pattern, value in patterns:\n",
    "                try:\n",
    "                    query = indigo.loadQueryMolecule(pattern)\n",
    "                    for match in matcher.iterateMatches(query):\n",
    "                        for qatom in query.iterateAtoms():\n",
    "                            atom = match.mapAtom(qatom)\n",
    "                            atom_values[atom.index()] += value / query.countAtoms()\n",
    "                except:\n",
    "                    pass\n",
    "            return atom_values\n",
    "        def addColorSGroups (m, atom_values):\n",
    "            min_value = min(atom_values.itervalues())\n",
    "            max_value = max(atom_values.itervalues())\n",
    "            centered_value = (min_value + max_value) / 2.\n",
    "            for atom_index, atom_value in atom_values.iteritems():\n",
    "                if atom_value < 0.:\n",
    "                    color = \"0, 0, %f\" % abs(atom_value / centered_value)\n",
    "                elif atom_value > 0.:\n",
    "                    color = \"%f, 0, 0\" % abs(atom_value / centered_value)\n",
    "                m.addDataSGroup([atom_index], [], \"color\", color)\n",
    "            return min_value, max_value\n",
    "\n",
    "        def assignColorGroups (m, patterns):\n",
    "            atom_values = getAtomsActivity(m, patterns)\n",
    "            min_value, max_value = addColorSGroups(m, atom_values)\n",
    "            return min_value, max_value\n",
    "        for count, (id, compound) in enumerate(self.testing.testing_data.compound.iteritems()):\n",
    "            id_name = id\n",
    "            print(count, id_name)\n",
    "            _base = 'pubchem.ncbi.nlm.nih.gov'\n",
    "            uri = '/rest/pug/compound/cid/' + str(id_name) + '/record/SDF'\n",
    "            uri = 'http://' + _base + uri\n",
    "            if not local:\n",
    "                response = urllib2.urlopen(uri)\n",
    "                value = response.read().strip().decode().strip('$$$$')\n",
    "                filename = \"data/\" + str(id_name) + \".sdf\"\n",
    "                text_file = open(filename, \"w\")\n",
    "                text_file.write(value)\n",
    "                text_file.close()\n",
    "            row = count\n",
    "            #Collect explanations from LIME\n",
    "            exp = self.explainer.explain_instance(self.testing.reduced_data_table[row],\n",
    "                                                  self.predict_fn,\n",
    "                                                  num_features=len(self.training.reduced_feature_patterns),\n",
    "                                                  top_labels=1, verbose=True, num_samples=5000)\n",
    "            #Load molecule\n",
    "            if local:\n",
    "                mol = indigo.iterateSDFile(local)\n",
    "                m = mol.at(count)\n",
    "            else:\n",
    "                mol = indigo.iterateSDFile(filename)\n",
    "                m = mol.at(0)\n",
    "            patterns = []\n",
    "            #Find the local explanation: exp.local_exp[1]\n",
    "            intercept = exp.intercept.keys()[0]\n",
    "            local_prob = exp.intercept.values()[0]\n",
    "            prob = exp.predict_proba[intercept]\n",
    "            for k, v in exp.local_exp.items():\n",
    "                for (num, val) in v:\n",
    "                    print(str(id_name), exp.domain_mapper.exp_feature_names[num], val)\n",
    "                #Map the explanation to the feature, if it is present in the molecule move forward\n",
    "                    if float(exp.domain_mapper.feature_values[num]) == 1.:\n",
    "                        if abs(val) != 0.:\n",
    "                            patterns.append((self.testing.reduced_feature_patterns[num], val))\n",
    "                #Draw molecules\n",
    "            indigo.setOption(\"render-atom-ids-visible\", \"false\");\n",
    "            indigo.setOption(\"render-atom-color-property\", \"color\")\n",
    "            indigo.setOption('render-coloring', False)\n",
    "            indigo.setOption('render-comment-font-size', 32)\n",
    "            indigo.setOption('render-bond-line-width', 2.0)\n",
    "            indigo.setOption(\"render-margins\", 100, 1);\n",
    "            indigo.setOption('render-comment', id_name)\n",
    "            try:\n",
    "                assignColorGroups(m, patterns)\n",
    "            except:\n",
    "                pass\n",
    "            renderfile = \"img/\" + str(self.identifier) + str(id_name) + \".png\"\n",
    "            indigoRenderer.renderToFile(m, renderfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_classifier(training_file, testing_file, roc_file, identifier, train=False, cv=True, visualize=True, lime=True, local=False, delim=\"\"):\n",
    "    if not train:\n",
    "        train = Train()\n",
    "        train.load(training_file, identifier)\n",
    "        train.reduce_features()\n",
    "        train.learn()\n",
    "    if cv:\n",
    "        CV = CrossValidate(train)\n",
    "        CV.cross_validation()\n",
    "        if visualize:\n",
    "            CV.visualize(roc_file)\n",
    "    test = Testing()\n",
    "    test.load(testing_file)\n",
    "    test.reduce_features(train)\n",
    "    test.learn(train)\n",
    "    if visualize:\n",
    "        viz = VisualizeTesting(train, test)\n",
    "        viz.pca()\n",
    "        var_file = delim + \"visualized_variance.png\"\n",
    "        viz.viz_explained(var_file)\n",
    "        xx_file = delim + \"visualized_xx.png\"\n",
    "        viz.viz_xx(xx_file)\n",
    "    if lime:\n",
    "        lime = LIME(train, test, identifier)\n",
    "        lime.molecule(local)\n",
    "    return(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.421875    0.578125  ]\n",
      " [ 0.59765625  0.40234375]\n",
      " [ 0.52148438  0.47851562]\n",
      " [ 0.56640625  0.43359375]\n",
      " [ 0.52539062  0.47460938]\n",
      " [ 0.72460938  0.27539062]\n",
      " [ 0.69921875  0.30078125]\n",
      " [ 0.51757812  0.48242188]\n",
      " [ 0.74023438  0.25976562]\n",
      " [ 0.52929688  0.47070312]\n",
      " [ 0.44921875  0.55078125]]\n",
      "['Tetrahydro-3,5-dimethyl-6-propyl-2H-pyran-2-one', '6-Ethyltetrahydro-2H-pyran-2-one', 'SCHEMBL13355779', 'CID_14101663', 'SCHEMBL5585129', '3,6-dimethyloxan-2-one', '2H-Pyran-2-one,tetrahydro-3,5,6-trimethyl-', '648434-43-9', '5,6-dimethyloxan-2-one', 'SCHEMBL13355780', 'SCHEMBL13355731']\n",
      "(0, '101410820')\n",
      "(1, '102968')\n",
      "(2, '14015767')\n",
      "(3, '14101663')\n",
      "(4, '15632339')\n",
      "(5, '19490')\n",
      "(6, '20717729')\n",
      "(7, '45095989')\n",
      "(8, '544628')\n",
      "(9, '73810187')\n",
      "(10, '78159702')\n",
      "[[ 0.66796875  0.33203125]\n",
      " [ 0.82617188  0.17382812]\n",
      " [ 0.734375    0.265625  ]\n",
      " [ 0.68554688  0.31445312]\n",
      " [ 0.75195312  0.24804688]\n",
      " [ 0.703125    0.296875  ]\n",
      " [ 0.54492188  0.45507812]\n",
      " [ 0.7421875   0.2578125 ]\n",
      " [ 0.74609375  0.25390625]]\n",
      "['2-Methyl-5-heptanone', 'SCHEMBL1369119', '4,6-Dimethyloctan-3-one', '4,6-Dimethyl-3-nonanone', '3,5-dimethylheptan-2-one', '6-Methyloctan-3-one', '4-Methylnonan-3-one', '5-methylheptan-2-one', '4,6-dimethylheptan-3-one']\n",
      "(0, '12210')\n",
      "(1, '12634596')\n",
      "(2, '13834046')\n",
      "(3, '13988330')\n",
      "(4, '13988337')\n",
      "(5, '14158008')\n",
      "(6, '19931295')\n",
      "(7, '28965')\n",
      "(8, '59154468')\n",
      "[[ 0.953125  0.046875]\n",
      " [ 0.921875  0.078125]]\n",
      "['3-Methyl-2-Pentanone', '4-Methylhexan-3-one']\n",
      "(0, '11262')\n",
      "(1, '86501')\n",
      "[[ 0.86914062  0.13085938]\n",
      " [ 0.875       0.125     ]\n",
      " [ 0.90429688  0.09570312]\n",
      " [ 0.61523438  0.38476562]\n",
      " [ 0.80664062  0.19335938]\n",
      " [ 0.5546875   0.4453125 ]\n",
      " [ 0.765625    0.234375  ]\n",
      " [ 0.62695312  0.37304688]\n",
      " [ 0.67773438  0.32226562]\n",
      " [ 0.68359375  0.31640625]\n",
      " [ 0.7890625   0.2109375 ]\n",
      " [ 0.70898438  0.29101562]\n",
      " [ 0.6875      0.3125    ]\n",
      " [ 0.765625    0.234375  ]\n",
      " [ 0.80273438  0.19726562]\n",
      " [ 0.79296875  0.20703125]\n",
      " [ 0.640625    0.359375  ]\n",
      " [ 0.65429688  0.34570312]\n",
      " [ 0.60546875  0.39453125]\n",
      " [ 0.76171875  0.23828125]\n",
      " [ 0.515625    0.484375  ]\n",
      " [ 0.59960938  0.40039062]\n",
      " [ 0.76367188  0.23632812]\n",
      " [ 0.78445418  0.21554582]\n",
      " [ 0.59375     0.40625   ]\n",
      " [ 0.80273438  0.19726562]\n",
      " [ 0.85742188  0.14257812]\n",
      " [ 0.7109375   0.2890625 ]\n",
      " [ 0.6875      0.3125    ]\n",
      " [ 0.77734375  0.22265625]\n",
      " [ 0.83398438  0.16601562]\n",
      " [ 0.6640625   0.3359375 ]\n",
      " [ 0.65039062  0.34960938]\n",
      " [ 0.4765625   0.5234375 ]\n",
      " [ 0.78710938  0.21289062]\n",
      " [ 0.6328125   0.3671875 ]\n",
      " [ 0.58789062  0.41210938]]\n",
      "['5-hydroxy-6-methylheptan-3-one', '5-hydroxy-4,6-dimethylheptan-3-one', '4-hydroxy-3,5-dimethylhexan-2-one', '6-propan-2-yloxane-2,4-dione', '5-hydroxy-4,6-dimethyloctan-3-one', '6-butan-2-yl-4-hydroxyoxan-2-one', '4-hydroxy-3,6-dimethyloxan-2-one', '4-hydroxy-3,5-dimethyl-6-propan-2-yloxan-2-one', '4-hydroxy-6-propan-2-yloxan-2-one', '4,6-dimethylnonane-3,5,7-trione', '5-methylheptane-2,4-dione', '6-ethyl-4-hydroxyoxan-2-one', '6-methyloctane-3,5-dione', '3,6-dimethyloxane-2,4-dione', '4-hydroxy-5,6-dimethyloxan-2-one', '5,6-dimethyloxane-2,4-dione', '6-ethyl-4-hydroxy-3-methyloxan-2-one', '6-ethyl-4-hydroxy-5-methyloxan-2-one', '6-ethyl-5-methyloxane-2,4-dione', '4-hydroxy-3,5,6-trimethyloxan-2-one', '6-butan-2-yl-4-hydroxy-3,5-dimethyloxan-2-one', '6-ethyl-4-hydroxy-3,5-dimethyloxan-2-one', '3,5,6-trimethyloxane-2,4-dione', '5,7-dihydroxy-4,6-dimethylnonan-3-one', '6-ethyl-3,5-dimethyloxane-2,4-dione', '2-methylheptane-3,5-dione', '3,5-dimethylhexane-2,4-dione', '3,5-dimethylheptane-2,4-dione', '4,6-dimethyloctane-3,5-dione', '2,4-dimethylheptane-3,5-dione', '4-hydroxy-5-methylheptan-2-one', '6-ethyloxane-2,4-dione', '4-hydroxy-5-methyl-6-propan-2-yloxan-2-one', '4-hydroxy-3,5-dimethyl-6-propyloxan-2-one', '5-hydroxy-4,6-dimethylnonane-3,7-dione', '4-hydroxy-3-methyl-6-propan-2-yloxan-2-one', '6-ethyl-3-methyloxane-2,4-dione']\n",
      "(0, '10396949')\n",
      "(1, '12262691')\n",
      "(2, '13172580')\n",
      "(3, '13250344')\n",
      "(4, '13426295')\n",
      "(5, '13858060')\n",
      "(6, '14175658')\n",
      "(7, '14175664')\n",
      "(8, '14194739')\n",
      "(9, '14754141')\n",
      "(10, '15825654')\n",
      "(11, '20679563')\n",
      "(12, '20702763')\n",
      "(13, '21337445')\n",
      "(14, '22962070')\n",
      "(15, '22962073')\n",
      "(16, '22962084')\n",
      "(17, '22962085')\n",
      "(18, '22962086')\n",
      "(19, '23397911')\n",
      "(20, '23397912')\n",
      "(21, '23397916')\n",
      "(22, '23597978')\n",
      "(23, '23597979')\n",
      "(24, '23597983')\n",
      "(25, '238496')\n",
      "(26, '2753146')\n",
      "(27, '527251')\n",
      "(28, '527253')\n",
      "(29, '545615')\n",
      "(30, '57287974')\n",
      "(31, '71344961')\n",
      "(32, '72775233')\n",
      "(33, '73116478')\n",
      "(34, '85419991')\n",
      "(35, '85434855')\n",
      "(36, '86079757')\n"
     ]
    }
   ],
   "source": [
    "training = run_classifier('cetane.txt', \"testing_data.txt\", 'testing_data.png', 'Cetane', cv=False, train=False, visualize=True, lime=True, delim=\"testing\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
